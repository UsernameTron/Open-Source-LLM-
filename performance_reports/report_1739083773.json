{
  "timestamp": "2025-02-09T00:49:33.064070",
  "overall_metrics": {
    "avg_latency_ms": 56.11261868476868,
    "p95_latency_ms": 266.1879062652588,
    "avg_gpu_utilization": 0.8000000000000002,
    "avg_memory_utilization": 0.536017
  },
  "batch_metrics": {
    "1": {
      "throughput": 17.62759501608437,
      "avg_latency_ms": 56.11261868476868,
      "p95_latency_ms": 266.1879062652588,
      "gpu_utilization": 0.8000000000000002,
      "memory_utilization": 0.536017,
      "accuracy": 1.0,
      "confidence_mean": 0.9946658273935318,
      "confidence_std": 0.001278693625488192
    }
  },
  "recommendations": [
    {
      "type": "latency",
      "severity": "high",
      "message": "P95 latency exceeds target of 100ms. Consider reducing batch size or implementing request queuing."
    },
    {
      "type": "gpu_utilization",
      "severity": "medium",
      "message": "GPU utilization below 80%. Consider increasing batch size or concurrent requests."
    },
    {
      "type": "batch_size",
      "severity": "info",
      "message": "Optimal batch size for throughput is 1. Consider adjusting dynamic batching thresholds."
    }
  ]
}