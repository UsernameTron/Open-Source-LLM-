{
  "timestamp": "2025-02-09T00:51:34.928468",
  "overall_metrics": {
    "avg_latency_ms": 175.70348286628723,
    "p95_latency_ms": 1059.5525979995728,
    "avg_gpu_utilization": 0.8000000000000002,
    "avg_memory_utilization": 0.54274
  },
  "batch_metrics": {
    "1": {
      "throughput": 5.659406221084381,
      "avg_latency_ms": 175.70348286628723,
      "p95_latency_ms": 1059.5525979995728,
      "gpu_utilization": 0.8000000000000002,
      "memory_utilization": 0.54274,
      "accuracy": 1.0,
      "confidence_mean": 0.9950203014016151,
      "confidence_std": 0.001359962656769542
    }
  },
  "recommendations": [
    {
      "type": "latency",
      "severity": "high",
      "message": "P95 latency exceeds target of 100ms. Consider reducing batch size or implementing request queuing."
    },
    {
      "type": "gpu_utilization",
      "severity": "medium",
      "message": "GPU utilization below 80%. Consider increasing batch size or concurrent requests."
    },
    {
      "type": "batch_size",
      "severity": "info",
      "message": "Optimal batch size for throughput is 1. Consider adjusting dynamic batching thresholds."
    }
  ]
}