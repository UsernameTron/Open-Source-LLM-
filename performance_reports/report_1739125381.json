{
  "timestamp": "2025-02-09T12:23:01.695131",
  "overall_metrics": {
    "avg_latency_ms": 10.203126952065126,
    "p95_latency_ms": 13.101578894751203,
    "avg_gpu_utilization": 0.6162724907442162,
    "avg_memory_utilization": 0.39604706681606516
  },
  "batch_metrics": {
    "8": {
      "throughput": 456805.38613861386,
      "avg_latency_ms": 10.203126952065126,
      "p95_latency_ms": 13.101578894751203,
      "gpu_utilization": 0.6162724907442162,
      "memory_utilization": 0.39604706681606516,
      "accuracy": 0.0,
      "confidence_mean": 0.7764666875696459,
      "confidence_std": 0.025223690717155474
    }
  },
  "recommendations": [
    {
      "type": "gpu_utilization",
      "severity": "medium",
      "message": "GPU utilization below 80%. Consider increasing batch size or concurrent requests."
    },
    {
      "type": "batch_size",
      "severity": "info",
      "message": "Optimal batch size for throughput is 8. Consider adjusting dynamic batching thresholds."
    }
  ]
}