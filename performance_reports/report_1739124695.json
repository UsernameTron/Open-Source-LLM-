{
  "timestamp": "2025-02-09T12:11:35.584898",
  "overall_metrics": {
    "avg_latency_ms": 9.376521476841397,
    "p95_latency_ms": 11.440597243132988,
    "avg_gpu_utilization": 0.5996093491376615,
    "avg_memory_utilization": 0.4153060319475463
  },
  "batch_metrics": {
    "8": {
      "throughput": 419430.4,
      "avg_latency_ms": 9.376521476841397,
      "p95_latency_ms": 11.440597243132988,
      "gpu_utilization": 0.5996093491376615,
      "memory_utilization": 0.4153060319475463,
      "accuracy": 0.0,
      "confidence_mean": 0.76906367060712,
      "confidence_std": 0.04069769937077159
    }
  },
  "recommendations": [
    {
      "type": "gpu_utilization",
      "severity": "medium",
      "message": "GPU utilization below 80%. Consider increasing batch size or concurrent requests."
    },
    {
      "type": "batch_size",
      "severity": "info",
      "message": "Optimal batch size for throughput is 8. Consider adjusting dynamic batching thresholds."
    }
  ]
}