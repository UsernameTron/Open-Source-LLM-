{
  "timestamp": "2025-02-09T00:50:33.950420",
  "overall_metrics": {
    "avg_latency_ms": 115.54977560043335,
    "p95_latency_ms": 543.181574344635,
    "avg_gpu_utilization": 0.8000000000000002,
    "avg_memory_utilization": 0.540233
  },
  "batch_metrics": {
    "1": {
      "throughput": 8.590669058192391,
      "avg_latency_ms": 115.54977560043335,
      "p95_latency_ms": 543.181574344635,
      "gpu_utilization": 0.8000000000000002,
      "memory_utilization": 0.540233,
      "accuracy": 1.0,
      "confidence_mean": 0.9948886886835099,
      "confidence_std": 0.0013268091308511376
    }
  },
  "recommendations": [
    {
      "type": "latency",
      "severity": "high",
      "message": "P95 latency exceeds target of 100ms. Consider reducing batch size or implementing request queuing."
    },
    {
      "type": "gpu_utilization",
      "severity": "medium",
      "message": "GPU utilization below 80%. Consider increasing batch size or concurrent requests."
    },
    {
      "type": "batch_size",
      "severity": "info",
      "message": "Optimal batch size for throughput is 1. Consider adjusting dynamic batching thresholds."
    }
  ]
}